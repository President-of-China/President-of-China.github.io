"use strict";(self.webpackChunk_lls_web_app=self.webpackChunk_lls_web_app||[]).push([[2845],{77131:(c,d,h)=>{var a,e,p;p=h(34713),e=h(34267),a=function(){class u{constructor(v={}){this.options=v,p.load(this.options,this.defaults,this),this.Events=new e(this),this._arr=[],this._resetPromise(),this._lastFlush=Date.now()}_resetPromise(){return this._promise=new this.Promise((v,l)=>this._resolve=v)}_flush(){return clearTimeout(this._timeout),this._lastFlush=Date.now(),this._resolve(),this.Events.trigger("batch",this._arr),this._arr=[],this._resetPromise()}add(v){var l;return this._arr.push(v),l=this._promise,this._arr.length===this.maxSize?this._flush():this.maxTime!=null&&this._arr.length===1&&(this._timeout=setTimeout(()=>this._flush(),this.maxTime)),l}}return u.prototype.defaults={maxTime:null,maxSize:null,Promise},u}.call(void 0),c.exports=a},5653:(c,d,h)=>{function a(y,P){return v(y)||e(y,P)||u()}function e(y,P){var s=[],g=!0,R=!1,I=void 0;try{for(var k=y[Symbol.iterator](),T;!(g=(T=k.next()).done)&&(s.push(T.value),!(P&&s.length===P));g=!0);}catch(C){R=!0,I=C}finally{try{!g&&k.return!=null&&k.return()}finally{if(R)throw I}}return s}function p(y){return v(y)||o(y)||u()}function u(){throw new TypeError("Invalid attempt to destructure non-iterable instance")}function o(y){if(Symbol.iterator in Object(y)||Object.prototype.toString.call(y)==="[object Arguments]")return Array.from(y)}function v(y){if(Array.isArray(y))return y}function l(y,P,s,g,R,I,k){try{var T=y[I](k),C=T.value}catch(A){s(A);return}T.done?P(C):Promise.resolve(C).then(g,R)}function i(y){return function(){var P=this,s=arguments;return new Promise(function(g,R){var I=y.apply(P,s);function k(C){l(I,g,R,k,T,"next",C)}function T(C){l(I,g,R,k,T,"throw",C)}k(void 0)})}}var r,m,x,b,n,f,t,_,w,E,S,O=[].splice;f=10,m=5,S=h(34713),t=h(9733),b=h(16477),n=h(92095),_=h(90609),x=h(34267),w=h(98751),E=h(99748),r=function(){class y{constructor(s={},...g){var R,I;this._addToQueue=this._addToQueue.bind(this),this._validateOptions(s,g),S.load(s,this.instanceDefaults,this),this._queues=new t(f),this._scheduled={},this._states=new w(["RECEIVED","QUEUED","RUNNING","EXECUTING"].concat(this.trackDoneStatus?["DONE"]:[])),this._limiter=null,this.Events=new x(this),this._submitLock=new E("submit",this.Promise),this._registerLock=new E("register",this.Promise),I=S.load(s,this.storeDefaults,{}),this._store=function(){if(this.datastore==="redis"||this.datastore==="ioredis"||this.connection!=null)return R=S.load(s,this.redisStoreDefaults,{}),new _(this,I,R);if(this.datastore==="local")return R=S.load(s,this.localStoreDefaults,{}),new n(this,I,R);throw new y.prototype.BottleneckError(`Invalid datastore type: ${this.datastore}`)}.call(this),this._queues.on("leftzero",()=>{var k;return(k=this._store.heartbeat)!=null&&typeof k.ref=="function"?k.ref():void 0}),this._queues.on("zero",()=>{var k;return(k=this._store.heartbeat)!=null&&typeof k.unref=="function"?k.unref():void 0})}_validateOptions(s,g){if(!(s!=null&&typeof s=="object"&&g.length===0))throw new y.prototype.BottleneckError("Bottleneck v2 takes a single object argument. Refer to https://github.com/SGrondin/bottleneck#upgrading-to-v2 if you're upgrading from Bottleneck v1.")}ready(){return this._store.ready}clients(){return this._store.clients}channel(){return`b_${this.id}`}channel_client(){return`b_${this.id}_${this._store.clientId}`}publish(s){return this._store.__publish__(s)}disconnect(s=!0){return this._store.__disconnect__(s)}chain(s){return this._limiter=s,this}queued(s){return this._queues.queued(s)}clusterQueued(){return this._store.__queued__()}empty(){return this.queued()===0&&this._submitLock.isEmpty()}running(){return this._store.__running__()}done(){return this._store.__done__()}jobStatus(s){return this._states.jobStatus(s)}jobs(s){return this._states.statusJobs(s)}counts(){return this._states.statusCounts()}_randomIndex(){return Math.random().toString(36).slice(2)}check(s=1){return this._store.__check__(s)}_clearGlobalState(s){return this._scheduled[s]!=null?(clearTimeout(this._scheduled[s].expiration),delete this._scheduled[s],!0):!1}_free(s,g,R,I){var k=this;return i(function*(){var T,C;try{var A=yield k._store.__free__(s,R.weight);if(C=A.running,k.Events.trigger("debug",`Freed ${R.id}`,I),C===0&&k.empty())return k.Events.trigger("idle")}catch(j){return T=j,k.Events.trigger("error",T)}})()}_run(s,g,R){var I,k,T;return g.doRun(),I=this._clearGlobalState.bind(this,s),T=this._run.bind(this,s,g),k=this._free.bind(this,s,g),this._scheduled[s]={timeout:setTimeout(()=>g.doExecute(this._limiter,I,T,k),R),expiration:g.options.expiration!=null?setTimeout(function(){return g.doExpire(I,T,k)},R+g.options.expiration):void 0,job:g}}_drainOne(s){return this._registerLock.schedule(()=>{var g,R,I,k,T;if(this.queued()===0)return this.Promise.resolve(null);T=this._queues.getFirst();var C=I=T.first();return k=C.options,g=C.args,s!=null&&k.weight>s?this.Promise.resolve(null):(this.Events.trigger("debug",`Draining ${k.id}`,{args:g,options:k}),R=this._randomIndex(),this._store.__register__(R,k.weight,k.expiration).then(({success:A,wait:j,reservoir:q})=>{var L;return this.Events.trigger("debug",`Drained ${k.id}`,{success:A,args:g,options:k}),A?(T.shift(),L=this.empty(),L&&this.Events.trigger("empty"),q===0&&this.Events.trigger("depleted",L),this._run(R,I,j),this.Promise.resolve(k.weight)):this.Promise.resolve(null)}))})}_drainAll(s,g=0){return this._drainOne(s).then(R=>{var I;return R!=null?(I=s!=null?s-R:s,this._drainAll(I,g+R)):this.Promise.resolve(g)}).catch(R=>this.Events.trigger("error",R))}_dropAllQueued(s){return this._queues.shiftAll(function(g){return g.doDrop({message:s})})}stop(s={}){var g,R;return s=S.load(s,this.stopDefaults),R=I=>{var k;return k=()=>{var T;return T=this._states.counts,T[0]+T[1]+T[2]+T[3]===I},new this.Promise((T,C)=>k()?T():this.on("done",()=>{if(k())return this.removeAllListeners("done"),T()}))},g=s.dropWaitingJobs?(this._run=function(I,k){return k.doDrop({message:s.dropErrorMessage})},this._drainOne=()=>this.Promise.resolve(null),this._registerLock.schedule(()=>this._submitLock.schedule(()=>{var I,k,T;k=this._scheduled;for(I in k)T=k[I],this.jobStatus(T.job.options.id)==="RUNNING"&&(clearTimeout(T.timeout),clearTimeout(T.expiration),T.job.doDrop({message:s.dropErrorMessage}));return this._dropAllQueued(s.dropErrorMessage),R(0)}))):this.schedule({priority:f-1,weight:0},()=>R(1)),this._receive=function(I){return I._reject(new y.prototype.BottleneckError(s.enqueueErrorMessage))},this.stop=()=>this.Promise.reject(new y.prototype.BottleneckError("stop() has already been called")),g}_addToQueue(s){var g=this;return i(function*(){var R,I,k,T,C,A,j;R=s.args,T=s.options;try{var q=yield g._store.__submit__(g.queued(),T.weight);C=q.reachedHWM,I=q.blocked,j=q.strategy}catch(L){return k=L,g.Events.trigger("debug",`Could not queue ${T.id}`,{args:R,options:T,error:k}),s.doDrop({error:k}),!1}return I?(s.doDrop(),!0):C&&(A=j===y.prototype.strategy.LEAK?g._queues.shiftLastFrom(T.priority):j===y.prototype.strategy.OVERFLOW_PRIORITY?g._queues.shiftLastFrom(T.priority+1):j===y.prototype.strategy.OVERFLOW?s:void 0,A!=null&&A.doDrop(),A==null||j===y.prototype.strategy.OVERFLOW)?(A==null&&s.doDrop(),C):(s.doQueue(C,I),g._queues.push(s),yield g._drainAll(),C)})()}_receive(s){return this._states.jobStatus(s.options.id)!=null?(s._reject(new y.prototype.BottleneckError(`A job with the same id already exists (id=${s.options.id})`)),!1):(s.doReceive(),this._submitLock.schedule(this._addToQueue,s))}submit(...s){var g,R,I,k,T,C,A;if(typeof s[0]=="function"){var j,q,L,z;T=s,j=T,q=p(j),R=q[0],s=q.slice(1),L=O.call(s,-1),z=a(L,1),g=z[0],k=S.load({},this.jobDefaults)}else{var N,G,K,M;C=s,N=C,G=p(N),k=G[0],R=G[1],s=G.slice(2),K=O.call(s,-1),M=a(K,1),g=M[0],k=S.load(k,this.jobDefaults)}return A=(...D)=>new this.Promise(function(B,V){return R(...D,function(...W){return(W[0]!=null?V:B)(W)})}),I=new b(A,s,k,this.jobDefaults,this.rejectOnDrop,this.Events,this._states,this.Promise),I.promise.then(function(D){return typeof g=="function"?g(...D):void 0}).catch(function(D){return Array.isArray(D)?typeof g=="function"?g(...D):void 0:typeof g=="function"?g(D):void 0}),this._receive(I)}schedule(...s){var g,R,I;if(typeof s[0]=="function"){var k=s,T=p(k);I=T[0],s=T.slice(1),R={}}else{var C=s,A=p(C);R=A[0],I=A[1],s=A.slice(2)}return g=new b(I,s,R,this.jobDefaults,this.rejectOnDrop,this.Events,this._states,this.Promise),this._receive(g),g.promise}wrap(s){var g,R;return g=this.schedule.bind(this),R=function(...k){return g(s.bind(this),...k)},R.withOptions=function(I,...k){return g(I,s,...k)},R}updateSettings(s={}){var g=this;return i(function*(){return yield g._store.__updateSettings__(S.overwrite(s,g.storeDefaults)),S.overwrite(s,g.instanceDefaults,g),g})()}currentReservoir(){return this._store.__currentReservoir__()}incrementReservoir(s=0){return this._store.__incrementReservoir__(s)}}return y.default=y,y.Events=x,y.version=y.prototype.version=h(75705).i,y.strategy=y.prototype.strategy={LEAK:1,OVERFLOW:2,OVERFLOW_PRIORITY:4,BLOCK:3},y.BottleneckError=y.prototype.BottleneckError=h(28209),y.Group=y.prototype.Group=h(84446),y.RedisConnection=y.prototype.RedisConnection=h(43941),y.IORedisConnection=y.prototype.IORedisConnection=h(78942),y.Batcher=y.prototype.Batcher=h(77131),y.prototype.jobDefaults={priority:m,weight:1,expiration:null,id:"<no-id>"},y.prototype.storeDefaults={maxConcurrent:null,minTime:0,highWater:null,strategy:y.prototype.strategy.LEAK,penalty:null,reservoir:null,reservoirRefreshInterval:null,reservoirRefreshAmount:null,reservoirIncreaseInterval:null,reservoirIncreaseAmount:null,reservoirIncreaseMaximum:null},y.prototype.localStoreDefaults={Promise,timeout:null,heartbeatInterval:250},y.prototype.redisStoreDefaults={Promise,timeout:null,heartbeatInterval:5e3,clientTimeout:1e4,Redis:null,clientOptions:{},clusterNodes:null,clearDatastore:!1,connection:null},y.prototype.instanceDefaults={datastore:"local",connection:null,id:"<no-id>",rejectOnDrop:!0,trackDoneStatus:!1,Promise},y.prototype.stopDefaults={enqueueErrorMessage:"This limiter has been stopped and cannot accept new jobs.",dropWaitingJobs:!0,dropErrorMessage:"This limiter has been stopped."},y}.call(void 0),c.exports=r},28209:c=>{var d;d=class extends Error{},c.exports=d},56493:c=>{var d;d=class{constructor(a,e){this.incr=a,this.decr=e,this._first=null,this._last=null,this.length=0}push(a){var e;this.length++,typeof this.incr=="function"&&this.incr(),e={value:a,prev:this._last,next:null},this._last!=null?(this._last.next=e,this._last=e):this._first=this._last=e}shift(){var a;if(this._first!=null)return this.length--,typeof this.decr=="function"&&this.decr(),a=this._first.value,(this._first=this._first.next)!=null?this._first.prev=null:this._last=null,a}first(){if(this._first!=null)return this._first.value}getArray(){var a,e,p;for(a=this._first,p=[];a!=null;)p.push((e=a,a=a.next,e.value));return p}forEachShift(a){var e;for(e=this.shift();e!=null;)a(e),e=this.shift()}debug(){var a,e,p,u,o;for(a=this._first,o=[];a!=null;)o.push((e=a,a=a.next,{value:e.value,prev:(p=e.prev)!=null?p.value:void 0,next:(u=e.next)!=null?u.value:void 0}));return o}},c.exports=d},34267:c=>{function d(e,p,u,o,v,l,i){try{var r=e[l](i),m=r.value}catch(x){u(x);return}r.done?p(m):Promise.resolve(m).then(o,v)}function h(e){return function(){var p=this,u=arguments;return new Promise(function(o,v){var l=e.apply(p,u);function i(m){d(l,o,v,i,r,"next",m)}function r(m){d(l,o,v,i,r,"throw",m)}i(void 0)})}}var a;a=class{constructor(p){if(this.instance=p,this._events={},this.instance.on!=null||this.instance.once!=null||this.instance.removeAllListeners!=null)throw new Error("An Emitter already exists for this object");this.instance.on=(u,o)=>this._addListener(u,"many",o),this.instance.once=(u,o)=>this._addListener(u,"once",o),this.instance.removeAllListeners=(u=null)=>u!=null?delete this._events[u]:this._events={}}_addListener(p,u,o){var v;return(v=this._events)[p]==null&&(v[p]=[]),this._events[p].push({cb:o,status:u}),this.instance}listenerCount(p){return this._events[p]!=null?this._events[p].length:0}trigger(p,...u){var o=this;return h(function*(){var v,l;try{return p!=="debug"&&o.trigger("debug",`Event triggered: ${p}`,u),o._events[p]==null?void 0:(o._events[p]=o._events[p].filter(function(i){return i.status!=="none"}),l=o._events[p].map(function(){var i=h(function*(r){var m,x;if(r.status!=="none"){r.status==="once"&&(r.status="none");try{return x=typeof r.cb=="function"?r.cb(...u):void 0,typeof(x!=null?x.then:void 0)=="function"?yield x:x}catch(b){return m=b,o.trigger("error",m),null}}});return function(r){return i.apply(this,arguments)}}()),(yield Promise.all(l)).find(function(i){return i!=null}))}catch(i){return v=i,o.trigger("error",v),null}})()}},c.exports=a},84446:(c,d,h)=>{function a(n,f){return u(n)||p(n,f)||e()}function e(){throw new TypeError("Invalid attempt to destructure non-iterable instance")}function p(n,f){var t=[],_=!0,w=!1,E=void 0;try{for(var S=n[Symbol.iterator](),O;!(_=(O=S.next()).done)&&(t.push(O.value),!(f&&t.length===f));_=!0);}catch(y){w=!0,E=y}finally{try{!_&&S.return!=null&&S.return()}finally{if(w)throw E}}return t}function u(n){if(Array.isArray(n))return n}function o(n,f,t,_,w,E,S){try{var O=n[E](S),y=O.value}catch(P){t(P);return}O.done?f(y):Promise.resolve(y).then(_,w)}function v(n){return function(){var f=this,t=arguments;return new Promise(function(_,w){var E=n.apply(f,t);function S(y){o(E,_,w,S,O,"next",y)}function O(y){o(E,_,w,S,O,"throw",y)}S(void 0)})}}var l,i,r,m,x,b;b=h(34713),l=h(34267),m=h(43941),r=h(78942),x=h(42511),i=function(){class n{constructor(t={}){this.deleteKey=this.deleteKey.bind(this),this.limiterOptions=t,b.load(this.limiterOptions,this.defaults,this),this.Events=new l(this),this.instances={},this.Bottleneck=h(5653),this._startAutoCleanup(),this.sharedConnection=this.connection!=null,this.connection==null&&(this.limiterOptions.datastore==="redis"?this.connection=new m(Object.assign({},this.limiterOptions,{Events:this.Events})):this.limiterOptions.datastore==="ioredis"&&(this.connection=new r(Object.assign({},this.limiterOptions,{Events:this.Events}))))}key(t=""){var _;return(_=this.instances[t])!=null?_:(()=>{var w;return w=this.instances[t]=new this.Bottleneck(Object.assign(this.limiterOptions,{id:`${this.id}-${t}`,timeout:this.timeout,connection:this.connection})),this.Events.trigger("created",w,t),w})()}deleteKey(t=""){var _=this;return v(function*(){var w,E;return E=_.instances[t],_.connection&&(w=yield _.connection.__runCommand__(["del",...x.allKeys(`${_.id}-${t}`)])),E!=null&&(delete _.instances[t],yield E.disconnect()),E!=null||w>0})()}limiters(){var t,_,w,E;_=this.instances,w=[];for(t in _)E=_[t],w.push({key:t,limiter:E});return w}keys(){return Object.keys(this.instances)}clusterKeys(){var t=this;return v(function*(){var _,w,E,S,O,y,P,s,g;if(t.connection==null)return t.Promise.resolve(t.keys());for(y=[],_=null,g=`b_${t.id}-`.length,w="_settings".length;_!==0;){var R=yield t.connection.__runCommand__(["scan",_!=null?_:0,"match",`b_${t.id}-*_settings`,"count",1e4]),I=a(R,2);for(s=I[0],E=I[1],_=~~s,S=0,P=E.length;S<P;S++)O=E[S],y.push(O.slice(g,-w))}return y})()}_startAutoCleanup(){var t=this,_;return clearInterval(this.interval),typeof(_=this.interval=setInterval(v(function*(){var w,E,S,O,y,P;y=Date.now(),S=t.instances,O=[];for(E in S){P=S[E];try{(yield P._store.__groupCheck__(y))?O.push(t.deleteKey(E)):O.push(void 0)}catch(s){w=s,O.push(P.Events.trigger("error",w))}}return O}),this.timeout/2)).unref=="function"?_.unref():void 0}updateSettings(t={}){if(b.overwrite(t,this.defaults,this),b.overwrite(t,t,this.limiterOptions),t.timeout!=null)return this._startAutoCleanup()}disconnect(t=!0){var _;if(!this.sharedConnection)return(_=this.connection)!=null?_.disconnect(t):void 0}}return n.prototype.defaults={timeout:1e3*60*5,connection:null,Promise,id:"group-key"},n}.call(void 0),c.exports=i},78942:(module,__unused_webpack_exports,__webpack_require__)=>{function _slicedToArray(c,d){return _arrayWithHoles(c)||_iterableToArrayLimit(c,d)||_nonIterableRest()}function _nonIterableRest(){throw new TypeError("Invalid attempt to destructure non-iterable instance")}function _iterableToArrayLimit(c,d){var h=[],a=!0,e=!1,p=void 0;try{for(var u=c[Symbol.iterator](),o;!(a=(o=u.next()).done)&&(h.push(o.value),!(d&&h.length===d));a=!0);}catch(v){e=!0,p=v}finally{try{!a&&u.return!=null&&u.return()}finally{if(e)throw p}}return h}function _arrayWithHoles(c){if(Array.isArray(c))return c}function asyncGeneratorStep(c,d,h,a,e,p,u){try{var o=c[p](u),v=o.value}catch(l){h(l);return}o.done?d(v):Promise.resolve(v).then(a,e)}function _asyncToGenerator(c){return function(){var d=this,h=arguments;return new Promise(function(a,e){var p=c.apply(d,h);function u(v){asyncGeneratorStep(p,a,e,u,o,"next",v)}function o(v){asyncGeneratorStep(p,a,e,u,o,"throw",v)}u(void 0)})}}var Events,IORedisConnection,Scripts,parser;parser=__webpack_require__(34713),Events=__webpack_require__(34267),Scripts=__webpack_require__(42511),IORedisConnection=function(){class IORedisConnection{constructor(options={}){parser.load(options,this.defaults,this),this.Redis==null&&(this.Redis=eval("require")("ioredis")),this.Events==null&&(this.Events=new Events(this)),this.terminated=!1,this.clusterNodes!=null?(this.client=new this.Redis.Cluster(this.clusterNodes,this.clientOptions),this.subscriber=new this.Redis.Cluster(this.clusterNodes,this.clientOptions)):this.client!=null&&this.client.duplicate==null?this.subscriber=new this.Redis.Cluster(this.client.startupNodes,this.client.options):(this.client==null&&(this.client=new this.Redis(this.clientOptions)),this.subscriber=this.client.duplicate()),this.limiters={},this.ready=this.Promise.all([this._setup(this.client,!1),this._setup(this.subscriber,!0)]).then(()=>(this._loadScripts(),{client:this.client,subscriber:this.subscriber}))}_setup(c,d){return c.setMaxListeners(0),new this.Promise((h,a)=>(c.on("error",e=>this.Events.trigger("error",e)),d&&c.on("message",(e,p)=>{var u;return(u=this.limiters[e])!=null?u._store.onMessage(e,p):void 0}),c.status==="ready"?h():c.once("ready",h)))}_loadScripts(){return Scripts.names.forEach(c=>this.client.defineCommand(c,{lua:Scripts.payload(c)}))}__runCommand__(c){var d=this;return _asyncToGenerator(function*(){var h,a;yield d.ready;var e=yield d.client.pipeline([c]).exec(),p=_slicedToArray(e,1),u=_slicedToArray(p[0],2);return h=u[0],a=u[1],a})()}__addLimiter__(c){return this.Promise.all([c.channel(),c.channel_client()].map(d=>new this.Promise((h,a)=>this.subscriber.subscribe(d,()=>(this.limiters[d]=c,h())))))}__removeLimiter__(c){var d=this;return[c.channel(),c.channel_client()].forEach(function(){var h=_asyncToGenerator(function*(a){return d.terminated||(yield d.subscriber.unsubscribe(a)),delete d.limiters[a]});return function(a){return h.apply(this,arguments)}}())}__scriptArgs__(c,d,h,a){var e;return e=Scripts.keys(c,d),[e.length].concat(e,h,a)}__scriptFn__(c){return this.client[c].bind(this.client)}disconnect(c=!0){var d,h,a,e;for(e=Object.keys(this.limiters),d=0,a=e.length;d<a;d++)h=e[d],clearInterval(this.limiters[h]._store.heartbeat);return this.limiters={},this.terminated=!0,c?this.Promise.all([this.client.quit(),this.subscriber.quit()]):(this.client.disconnect(),this.subscriber.disconnect(),this.Promise.resolve())}}return IORedisConnection.prototype.datastore="ioredis",IORedisConnection.prototype.defaults={Redis:null,clientOptions:{},clusterNodes:null,client:null,Promise,Events:null},IORedisConnection}.call(void 0),module.exports=IORedisConnection},16477:(c,d,h)=>{function a(i,r,m,x,b,n,f){try{var t=i[n](f),_=t.value}catch(w){m(w);return}t.done?r(_):Promise.resolve(_).then(x,b)}function e(i){return function(){var r=this,m=arguments;return new Promise(function(x,b){var n=i.apply(r,m);function f(_){a(n,x,b,f,t,"next",_)}function t(_){a(n,x,b,f,t,"throw",_)}f(void 0)})}}var p,u,o,v,l;v=10,u=5,l=h(34713),p=h(28209),o=class{constructor(r,m,x,b,n,f,t,_){this.task=r,this.args=m,this.rejectOnDrop=n,this.Events=f,this._states=t,this.Promise=_,this.options=l.load(x,b),this.options.priority=this._sanitizePriority(this.options.priority),this.options.id===b.id&&(this.options.id=`${this.options.id}-${this._randomIndex()}`),this.promise=new this.Promise((w,E)=>{this._resolve=w,this._reject=E}),this.retryCount=0}_sanitizePriority(r){var m;return m=~~r!==r?u:r,m<0?0:m>v-1?v-1:m}_randomIndex(){return Math.random().toString(36).slice(2)}doDrop({error:r,message:m="This job has been dropped by Bottleneck"}={}){return this._states.remove(this.options.id)?(this.rejectOnDrop&&this._reject(r!=null?r:new p(m)),this.Events.trigger("dropped",{args:this.args,options:this.options,task:this.task,promise:this.promise}),!0):!1}_assertStatus(r){var m;if(m=this._states.jobStatus(this.options.id),!(m===r||r==="DONE"&&m===null))throw new p(`Invalid job status ${m}, expected ${r}. Please open an issue at https://github.com/SGrondin/bottleneck/issues`)}doReceive(){return this._states.start(this.options.id),this.Events.trigger("received",{args:this.args,options:this.options})}doQueue(r,m){return this._assertStatus("RECEIVED"),this._states.next(this.options.id),this.Events.trigger("queued",{args:this.args,options:this.options,reachedHWM:r,blocked:m})}doRun(){return this.retryCount===0?(this._assertStatus("QUEUED"),this._states.next(this.options.id)):this._assertStatus("EXECUTING"),this.Events.trigger("scheduled",{args:this.args,options:this.options})}doExecute(r,m,x,b){var n=this;return e(function*(){var f,t,_;n.retryCount===0?(n._assertStatus("RUNNING"),n._states.next(n.options.id)):n._assertStatus("EXECUTING"),t={args:n.args,options:n.options,retryCount:n.retryCount},n.Events.trigger("executing",t);try{if(_=yield r!=null?r.schedule(n.options,n.task,...n.args):n.task(...n.args),m())return n.doDone(t),yield b(n.options,t),n._assertStatus("DONE"),n._resolve(_)}catch(w){return f=w,n._onFailure(f,t,m,x,b)}})()}doExpire(r,m,x){var b,n;return this._states.jobStatus(this.options.id==="RUNNING")&&this._states.next(this.options.id),this._assertStatus("EXECUTING"),n={args:this.args,options:this.options,retryCount:this.retryCount},b=new p(`This job timed out after ${this.options.expiration} ms.`),this._onFailure(b,n,r,m,x)}_onFailure(r,m,x,b,n){var f=this;return e(function*(){var t,_;if(x())return t=yield f.Events.trigger("failed",r,m),t!=null?(_=~~t,f.Events.trigger("retry",`Retrying ${f.options.id} after ${_} ms`,m),f.retryCount++,b(_)):(f.doDone(m),yield n(f.options,m),f._assertStatus("DONE"),f._reject(r))})()}doDone(r){return this._assertStatus("EXECUTING"),this._states.next(this.options.id),this.Events.trigger("done",r)}},c.exports=o},92095:(c,d,h)=>{function a(v,l,i,r,m,x,b){try{var n=v[x](b),f=n.value}catch(t){i(t);return}n.done?l(f):Promise.resolve(f).then(r,m)}function e(v){return function(){var l=this,i=arguments;return new Promise(function(r,m){var x=v.apply(l,i);function b(f){a(x,r,m,b,n,"next",f)}function n(f){a(x,r,m,b,n,"throw",f)}b(void 0)})}}var p,u,o;o=h(34713),p=h(28209),u=class{constructor(l,i,r){this.instance=l,this.storeOptions=i,this.clientId=this.instance._randomIndex(),o.load(r,r,this),this._nextRequest=this._lastReservoirRefresh=this._lastReservoirIncrease=Date.now(),this._running=0,this._done=0,this._unblockTime=0,this.ready=this.Promise.resolve(),this.clients={},this._startHeartbeat()}_startHeartbeat(){var l;return this.heartbeat==null&&(this.storeOptions.reservoirRefreshInterval!=null&&this.storeOptions.reservoirRefreshAmount!=null||this.storeOptions.reservoirIncreaseInterval!=null&&this.storeOptions.reservoirIncreaseAmount!=null)?typeof(l=this.heartbeat=setInterval(()=>{var i,r,m,x,b;if(x=Date.now(),this.storeOptions.reservoirRefreshInterval!=null&&x>=this._lastReservoirRefresh+this.storeOptions.reservoirRefreshInterval&&(this._lastReservoirRefresh=x,this.storeOptions.reservoir=this.storeOptions.reservoirRefreshAmount,this.instance._drainAll(this.computeCapacity())),this.storeOptions.reservoirIncreaseInterval!=null&&x>=this._lastReservoirIncrease+this.storeOptions.reservoirIncreaseInterval){var n=this.storeOptions;if(i=n.reservoirIncreaseAmount,m=n.reservoirIncreaseMaximum,b=n.reservoir,this._lastReservoirIncrease=x,r=m!=null?Math.min(i,m-b):i,r>0)return this.storeOptions.reservoir+=r,this.instance._drainAll(this.computeCapacity())}},this.heartbeatInterval)).unref=="function"?l.unref():void 0:clearInterval(this.heartbeat)}__publish__(l){var i=this;return e(function*(){return yield i.yieldLoop(),i.instance.Events.trigger("message",l.toString())})()}__disconnect__(l){var i=this;return e(function*(){return yield i.yieldLoop(),clearInterval(i.heartbeat),i.Promise.resolve()})()}yieldLoop(l=0){return new this.Promise(function(i,r){return setTimeout(i,l)})}computePenalty(){var l;return(l=this.storeOptions.penalty)!=null?l:15*this.storeOptions.minTime||5e3}__updateSettings__(l){var i=this;return e(function*(){return yield i.yieldLoop(),o.overwrite(l,l,i.storeOptions),i._startHeartbeat(),i.instance._drainAll(i.computeCapacity()),!0})()}__running__(){var l=this;return e(function*(){return yield l.yieldLoop(),l._running})()}__queued__(){var l=this;return e(function*(){return yield l.yieldLoop(),l.instance.queued()})()}__done__(){var l=this;return e(function*(){return yield l.yieldLoop(),l._done})()}__groupCheck__(l){var i=this;return e(function*(){return yield i.yieldLoop(),i._nextRequest+i.timeout<l})()}computeCapacity(){var l,i,r=this.storeOptions;return l=r.maxConcurrent,i=r.reservoir,l!=null&&i!=null?Math.min(l-this._running,i):l!=null?l-this._running:i!=null?i:null}conditionsCheck(l){var i;return i=this.computeCapacity(),i==null||l<=i}__incrementReservoir__(l){var i=this;return e(function*(){var r;return yield i.yieldLoop(),r=i.storeOptions.reservoir+=l,i.instance._drainAll(i.computeCapacity()),r})()}__currentReservoir__(){var l=this;return e(function*(){return yield l.yieldLoop(),l.storeOptions.reservoir})()}isBlocked(l){return this._unblockTime>=l}check(l,i){return this.conditionsCheck(l)&&this._nextRequest-i<=0}__check__(l){var i=this;return e(function*(){var r;return yield i.yieldLoop(),r=Date.now(),i.check(l,r)})()}__register__(l,i,r){var m=this;return e(function*(){var x,b;return yield m.yieldLoop(),x=Date.now(),m.conditionsCheck(i)?(m._running+=i,m.storeOptions.reservoir!=null&&(m.storeOptions.reservoir-=i),b=Math.max(m._nextRequest-x,0),m._nextRequest=x+b+m.storeOptions.minTime,{success:!0,wait:b,reservoir:m.storeOptions.reservoir}):{success:!1}})()}strategyIsBlock(){return this.storeOptions.strategy===3}__submit__(l,i){var r=this;return e(function*(){var m,x,b;if(yield r.yieldLoop(),r.storeOptions.maxConcurrent!=null&&i>r.storeOptions.maxConcurrent)throw new p(`Impossible to add a job having a weight of ${i} to a limiter having a maxConcurrent setting of ${r.storeOptions.maxConcurrent}`);return x=Date.now(),b=r.storeOptions.highWater!=null&&l===r.storeOptions.highWater&&!r.check(i,x),m=r.strategyIsBlock()&&(b||r.isBlocked(x)),m&&(r._unblockTime=x+r.computePenalty(),r._nextRequest=r._unblockTime+r.storeOptions.minTime,r.instance._dropAllQueued()),{reachedHWM:b,blocked:m,strategy:r.storeOptions.strategy}})()}__free__(l,i){var r=this;return e(function*(){return yield r.yieldLoop(),r._running-=i,r._done+=i,r.instance._drainAll(r.computeCapacity()),{running:r._running}})()}},c.exports=u},9733:(c,d,h)=>{var a,e,p;a=h(56493),e=h(34267),p=class{constructor(o){var v;this.Events=new e(this),this._length=0,this._lists=function(){var l,i,r;for(r=[],v=l=1,i=o;1<=i?l<=i:l>=i;v=1<=i?++l:--l)r.push(new a(()=>this.incr(),()=>this.decr()));return r}.call(this)}incr(){if(this._length++===0)return this.Events.trigger("leftzero")}decr(){if(--this._length===0)return this.Events.trigger("zero")}push(o){return this._lists[o.options.priority].push(o)}queued(o){return o!=null?this._lists[o].length:this._length}shiftAll(o){return this._lists.forEach(function(v){return v.forEachShift(o)})}getFirst(o=this._lists){var v,l,i;for(v=0,l=o.length;v<l;v++)if(i=o[v],i.length>0)return i;return[]}shiftLastFrom(o){return this.getFirst(this._lists.slice(o).reverse()).shift()}},c.exports=p},43941:(module,__unused_webpack_exports,__webpack_require__)=>{function asyncGeneratorStep(c,d,h,a,e,p,u){try{var o=c[p](u),v=o.value}catch(l){h(l);return}o.done?d(v):Promise.resolve(v).then(a,e)}function _asyncToGenerator(c){return function(){var d=this,h=arguments;return new Promise(function(a,e){var p=c.apply(d,h);function u(v){asyncGeneratorStep(p,a,e,u,o,"next",v)}function o(v){asyncGeneratorStep(p,a,e,u,o,"throw",v)}u(void 0)})}}var Events,RedisConnection,Scripts,parser;parser=__webpack_require__(34713),Events=__webpack_require__(34267),Scripts=__webpack_require__(42511),RedisConnection=function(){class RedisConnection{constructor(options={}){parser.load(options,this.defaults,this),this.Redis==null&&(this.Redis=eval("require")("redis")),this.Events==null&&(this.Events=new Events(this)),this.terminated=!1,this.client==null&&(this.client=this.Redis.createClient(this.clientOptions)),this.subscriber=this.client.duplicate(),this.limiters={},this.shas={},this.ready=this.Promise.all([this._setup(this.client,!1),this._setup(this.subscriber,!0)]).then(()=>this._loadScripts()).then(()=>({client:this.client,subscriber:this.subscriber}))}_setup(c,d){return c.setMaxListeners(0),new this.Promise((h,a)=>(c.on("error",e=>this.Events.trigger("error",e)),d&&c.on("message",(e,p)=>{var u;return(u=this.limiters[e])!=null?u._store.onMessage(e,p):void 0}),c.ready?h():c.once("ready",h)))}_loadScript(c){return new this.Promise((d,h)=>{var a;return a=Scripts.payload(c),this.client.multi([["script","load",a]]).exec((e,p)=>e!=null?h(e):(this.shas[c]=p[0],d(p[0])))})}_loadScripts(){return this.Promise.all(Scripts.names.map(c=>this._loadScript(c)))}__runCommand__(c){var d=this;return _asyncToGenerator(function*(){return yield d.ready,new d.Promise((h,a)=>d.client.multi([c]).exec_atomic(function(e,p){return e!=null?a(e):h(p[0])}))})()}__addLimiter__(c){return this.Promise.all([c.channel(),c.channel_client()].map(d=>new this.Promise((h,a)=>{var e;return e=p=>{if(p===d)return this.subscriber.removeListener("subscribe",e),this.limiters[d]=c,h()},this.subscriber.on("subscribe",e),this.subscriber.subscribe(d)})))}__removeLimiter__(c){var d=this;return this.Promise.all([c.channel(),c.channel_client()].map(function(){var h=_asyncToGenerator(function*(a){return d.terminated||(yield new d.Promise((e,p)=>d.subscriber.unsubscribe(a,function(u,o){if(u!=null)return p(u);if(o===a)return e()}))),delete d.limiters[a]});return function(a){return h.apply(this,arguments)}}()))}__scriptArgs__(c,d,h,a){var e;return e=Scripts.keys(c,d),[this.shas[c],e.length].concat(e,h,a)}__scriptFn__(c){return this.client.evalsha.bind(this.client)}disconnect(c=!0){var d,h,a,e;for(e=Object.keys(this.limiters),d=0,a=e.length;d<a;d++)h=e[d],clearInterval(this.limiters[h]._store.heartbeat);return this.limiters={},this.terminated=!0,this.client.end(c),this.subscriber.end(c),this.Promise.resolve()}}return RedisConnection.prototype.datastore="redis",RedisConnection.prototype.defaults={Redis:null,clientOptions:{},client:null,Promise,Events:null},RedisConnection}.call(void 0),module.exports=RedisConnection},90609:(c,d,h)=>{function a(b,n){return u(b)||p(b,n)||e()}function e(){throw new TypeError("Invalid attempt to destructure non-iterable instance")}function p(b,n){var f=[],t=!0,_=!1,w=void 0;try{for(var E=b[Symbol.iterator](),S;!(t=(S=E.next()).done)&&(f.push(S.value),!(n&&f.length===n));t=!0);}catch(O){_=!0,w=O}finally{try{!t&&E.return!=null&&E.return()}finally{if(_)throw w}}return f}function u(b){if(Array.isArray(b))return b}function o(b,n,f,t,_,w,E){try{var S=b[w](E),O=S.value}catch(y){f(y);return}S.done?n(O):Promise.resolve(O).then(t,_)}function v(b){return function(){var n=this,f=arguments;return new Promise(function(t,_){var w=b.apply(n,f);function E(O){o(w,t,_,E,S,"next",O)}function S(O){o(w,t,_,E,S,"throw",O)}E(void 0)})}}var l,i,r,m,x;x=h(34713),l=h(28209),r=h(43941),i=h(78942),m=class{constructor(n,f,t){this.instance=n,this.storeOptions=f,this.originalId=this.instance.id,this.clientId=this.instance._randomIndex(),x.load(t,t,this),this.clients={},this.capacityPriorityCounters={},this.sharedConnection=this.connection!=null,this.connection==null&&(this.connection=this.instance.datastore==="redis"?new r({Redis:this.Redis,clientOptions:this.clientOptions,Promise:this.Promise,Events:this.instance.Events}):this.instance.datastore==="ioredis"?new i({Redis:this.Redis,clientOptions:this.clientOptions,clusterNodes:this.clusterNodes,Promise:this.Promise,Events:this.instance.Events}):void 0),this.instance.connection=this.connection,this.instance.datastore=this.connection.datastore,this.ready=this.connection.ready.then(_=>(this.clients=_,this.runScript("init",this.prepareInitSettings(this.clearDatastore)))).then(()=>this.connection.__addLimiter__(this.instance)).then(()=>this.runScript("register_client",[this.instance.queued()])).then(()=>{var _;return typeof(_=this.heartbeat=setInterval(()=>this.runScript("heartbeat",[]).catch(w=>this.instance.Events.trigger("error",w)),this.heartbeatInterval)).unref=="function"&&_.unref(),this.clients})}__publish__(n){var f=this;return v(function*(){var t,_=yield f.ready;return t=_.client,t.publish(f.instance.channel(),`message:${n.toString()}`)})()}onMessage(n,f){var t=this;return v(function*(){var _,w,E,S,O,y,P,s,g,R;try{P=f.indexOf(":");var I=[f.slice(0,P),f.slice(P+1)];if(R=I[0],E=I[1],R==="capacity")return yield t.instance._drainAll(E.length>0?~~E:void 0);if(R==="capacity-priority"){var k=E.split(":"),T=a(k,3);return g=T[0],s=T[1],w=T[2],_=g.length>0?~~g:void 0,s===t.clientId?(S=yield t.instance._drainAll(_),y=_!=null?_-(S||0):"",yield t.clients.client.publish(t.instance.channel(),`capacity-priority:${y}::${w}`)):s===""?(clearTimeout(t.capacityPriorityCounters[w]),delete t.capacityPriorityCounters[w],t.instance._drainAll(_)):t.capacityPriorityCounters[w]=setTimeout(v(function*(){var C;try{return delete t.capacityPriorityCounters[w],yield t.runScript("blacklist_client",[s]),yield t.instance._drainAll(_)}catch(A){return C=A,t.instance.Events.trigger("error",C)}}),1e3)}else{if(R==="message")return t.instance.Events.trigger("message",E);if(R==="blocked")return yield t.instance._dropAllQueued()}}catch(C){return O=C,t.instance.Events.trigger("error",O)}})()}__disconnect__(n){return clearInterval(this.heartbeat),this.sharedConnection?this.connection.__removeLimiter__(this.instance):this.connection.disconnect(n)}runScript(n,f){var t=this;return v(function*(){return n==="init"||n==="register_client"||(yield t.ready),new t.Promise((_,w)=>{var E,S;return E=[Date.now(),t.clientId].concat(f),t.instance.Events.trigger("debug",`Calling Redis script: ${n}.lua`,E),S=t.connection.__scriptArgs__(n,t.originalId,E,function(O,y){return O!=null?w(O):_(y)}),t.connection.__scriptFn__(n)(...S)}).catch(_=>_.message==="SETTINGS_KEY_NOT_FOUND"?n==="heartbeat"?t.Promise.resolve():t.runScript("init",t.prepareInitSettings(!1)).then(()=>t.runScript(n,f)):_.message==="UNKNOWN_CLIENT"?t.runScript("register_client",[t.instance.queued()]).then(()=>t.runScript(n,f)):t.Promise.reject(_))})()}prepareArray(n){var f,t,_,w;for(_=[],f=0,t=n.length;f<t;f++)w=n[f],_.push(w!=null?w.toString():"");return _}prepareObject(n){var f,t,_;f=[];for(t in n)_=n[t],f.push(t,_!=null?_.toString():"");return f}prepareInitSettings(n){var f;return f=this.prepareObject(Object.assign({},this.storeOptions,{id:this.originalId,version:this.instance.version,groupTimeout:this.timeout,clientTimeout:this.clientTimeout})),f.unshift(n?1:0,this.instance.version),f}convertBool(n){return!!n}__updateSettings__(n){var f=this;return v(function*(){return yield f.runScript("update_settings",f.prepareObject(n)),x.overwrite(n,n,f.storeOptions)})()}__running__(){return this.runScript("running",[])}__queued__(){return this.runScript("queued",[])}__done__(){return this.runScript("done",[])}__groupCheck__(){var n=this;return v(function*(){return n.convertBool(yield n.runScript("group_check",[]))})()}__incrementReservoir__(n){return this.runScript("increment_reservoir",[n])}__currentReservoir__(){return this.runScript("current_reservoir",[])}__check__(n){var f=this;return v(function*(){return f.convertBool(yield f.runScript("check",f.prepareArray([n])))})()}__register__(n,f,t){var _=this;return v(function*(){var w,E,S,O=yield _.runScript("register",_.prepareArray([n,f,t])),y=a(O,3);return E=y[0],S=y[1],w=y[2],{success:_.convertBool(E),wait:S,reservoir:w}})()}__submit__(n,f){var t=this;return v(function*(){var _,w,E,S,O,y;try{var P=yield t.runScript("submit",t.prepareArray([n,f])),s=a(P,3);return O=s[0],_=s[1],y=s[2],{reachedHWM:t.convertBool(O),blocked:t.convertBool(_),strategy:y}}catch(I){if(w=I,w.message.indexOf("OVERWEIGHT")===0){var g=w.message.split(":"),R=a(g,3);throw S=R[0],f=R[1],E=R[2],new l(`Impossible to add a job having a weight of ${f} to a limiter having a maxConcurrent setting of ${E}`)}else throw w}})()}__free__(n,f){var t=this;return v(function*(){var _;return _=yield t.runScript("free",t.prepareArray([n])),{running:_}})()}},c.exports=m},42511:(c,d,h)=>{var a,e,p;e=h(40285),a={refs:e["refs.lua"],validate_keys:e["validate_keys.lua"],validate_client:e["validate_client.lua"],refresh_expiration:e["refresh_expiration.lua"],process_tick:e["process_tick.lua"],conditions_check:e["conditions_check.lua"],get_time:e["get_time.lua"]},d.allKeys=function(u){return[`b_${u}_settings`,`b_${u}_job_weights`,`b_${u}_job_expirations`,`b_${u}_job_clients`,`b_${u}_client_running`,`b_${u}_client_num_queued`,`b_${u}_client_last_registered`,`b_${u}_client_last_seen`]},p={init:{keys:d.allKeys,headers:["process_tick"],refresh_expiration:!0,code:e["init.lua"]},group_check:{keys:d.allKeys,headers:[],refresh_expiration:!1,code:e["group_check.lua"]},register_client:{keys:d.allKeys,headers:["validate_keys"],refresh_expiration:!1,code:e["register_client.lua"]},blacklist_client:{keys:d.allKeys,headers:["validate_keys","validate_client"],refresh_expiration:!1,code:e["blacklist_client.lua"]},heartbeat:{keys:d.allKeys,headers:["validate_keys","validate_client","process_tick"],refresh_expiration:!1,code:e["heartbeat.lua"]},update_settings:{keys:d.allKeys,headers:["validate_keys","validate_client","process_tick"],refresh_expiration:!0,code:e["update_settings.lua"]},running:{keys:d.allKeys,headers:["validate_keys","validate_client","process_tick"],refresh_expiration:!1,code:e["running.lua"]},queued:{keys:d.allKeys,headers:["validate_keys","validate_client"],refresh_expiration:!1,code:e["queued.lua"]},done:{keys:d.allKeys,headers:["validate_keys","validate_client","process_tick"],refresh_expiration:!1,code:e["done.lua"]},check:{keys:d.allKeys,headers:["validate_keys","validate_client","process_tick","conditions_check"],refresh_expiration:!1,code:e["check.lua"]},submit:{keys:d.allKeys,headers:["validate_keys","validate_client","process_tick","conditions_check"],refresh_expiration:!0,code:e["submit.lua"]},register:{keys:d.allKeys,headers:["validate_keys","validate_client","process_tick","conditions_check"],refresh_expiration:!0,code:e["register.lua"]},free:{keys:d.allKeys,headers:["validate_keys","validate_client","process_tick"],refresh_expiration:!0,code:e["free.lua"]},current_reservoir:{keys:d.allKeys,headers:["validate_keys","validate_client","process_tick"],refresh_expiration:!1,code:e["current_reservoir.lua"]},increment_reservoir:{keys:d.allKeys,headers:["validate_keys","validate_client","process_tick"],refresh_expiration:!0,code:e["increment_reservoir.lua"]}},d.names=Object.keys(p),d.keys=function(u,o){return p[u].keys(o)},d.payload=function(u){var o;return o=p[u],Array.prototype.concat(a.refs,o.headers.map(function(v){return a[v]}),o.refresh_expiration?a.refresh_expiration:"",o.code).join(`
`)}},98751:(c,d,h)=>{var a,e;a=h(28209),e=class{constructor(u){this.status=u,this._jobs={},this.counts=this.status.map(function(){return 0})}next(u){var o,v;if(o=this._jobs[u],v=o+1,o!=null&&v<this.status.length)return this.counts[o]--,this.counts[v]++,this._jobs[u]++;if(o!=null)return this.counts[o]--,delete this._jobs[u]}start(u){var o;return o=0,this._jobs[u]=o,this.counts[o]++}remove(u){var o;return o=this._jobs[u],o!=null&&(this.counts[o]--,delete this._jobs[u]),o!=null}jobStatus(u){var o;return(o=this.status[this._jobs[u]])!=null?o:null}statusJobs(u){var o,v,l,i,r;if(u!=null){if(v=this.status.indexOf(u),v<0)throw new a(`status must be one of ${this.status.join(", ")}`);l=this._jobs,i=[];for(o in l)r=l[o],r===v&&i.push(o);return i}else return Object.keys(this._jobs)}statusCounts(){return this.counts.reduce((u,o,v)=>(u[this.status[v]]=o,u),{})}},c.exports=e},99748:(c,d,h)=>{function a(o,v,l,i,r,m,x){try{var b=o[m](x),n=b.value}catch(f){l(f);return}b.done?v(n):Promise.resolve(n).then(i,r)}function e(o){return function(){var v=this,l=arguments;return new Promise(function(i,r){var m=o.apply(v,l);function x(n){a(m,i,r,x,b,"next",n)}function b(n){a(m,i,r,x,b,"throw",n)}x(void 0)})}}var p,u;p=h(56493),u=class{constructor(v,l){this.schedule=this.schedule.bind(this),this.name=v,this.Promise=l,this._running=0,this._queue=new p}isEmpty(){return this._queue.length===0}_tryToRun(){var v=this;return e(function*(){var l,i,r,m,x,b,n;if(v._running<1&&v._queue.length>0){v._running++;var f=v._queue.shift();return n=f.task,l=f.args,x=f.resolve,m=f.reject,i=yield e(function*(){try{return b=yield n(...l),function(){return x(b)}}catch(t){return r=t,function(){return m(r)}}})(),v._running--,v._tryToRun(),i()}})()}schedule(v,...l){var i,r,m;return m=r=null,i=new this.Promise(function(x,b){return m=x,r=b}),this._queue.push({task:v,args:l,resolve:m,reject:r}),this._tryToRun(),i}},c.exports=u},72873:(c,d,h)=>{c.exports=h(5653)},34713:(c,d)=>{d.load=function(h,a,e={}){var p,u,o;for(p in a)o=a[p],e[p]=(u=h[p])!=null?u:o;return e},d.overwrite=function(h,a,e={}){var p,u;for(p in h)u=h[p],a[p]!==void 0&&(e[p]=u);return e}},40285:c=>{c.exports=JSON.parse(`{"blacklist_client.lua":"local blacklist = ARGV[num_static_argv + 1]\\n\\nif redis.call('zscore', client_last_seen_key, blacklist) then\\n  redis.call('zadd', client_last_seen_key, 0, blacklist)\\nend\\n\\n\\nreturn {}\\n","check.lua":"local weight = tonumber(ARGV[num_static_argv + 1])\\n\\nlocal capacity = process_tick(now, false)['capacity']\\nlocal nextRequest = tonumber(redis.call('hget', settings_key, 'nextRequest'))\\n\\nreturn conditions_check(capacity, weight) and nextRequest - now <= 0\\n","conditions_check.lua":"local conditions_check = function (capacity, weight)\\n  return capacity == nil or weight <= capacity\\nend\\n","current_reservoir.lua":"return process_tick(now, false)['reservoir']\\n","done.lua":"process_tick(now, false)\\n\\nreturn tonumber(redis.call('hget', settings_key, 'done'))\\n","free.lua":"local index = ARGV[num_static_argv + 1]\\n\\nredis.call('zadd', job_expirations_key, 0, index)\\n\\nreturn process_tick(now, false)['running']\\n","get_time.lua":"redis.replicate_commands()\\n\\nlocal get_time = function ()\\n  local time = redis.call('time')\\n\\n  return tonumber(time[1]..string.sub(time[2], 1, 3))\\nend\\n","group_check.lua":"return not (redis.call('exists', settings_key) == 1)\\n","heartbeat.lua":"process_tick(now, true)\\n","increment_reservoir.lua":"local incr = tonumber(ARGV[num_static_argv + 1])\\n\\nredis.call('hincrby', settings_key, 'reservoir', incr)\\n\\nlocal reservoir = process_tick(now, true)['reservoir']\\n\\nlocal groupTimeout = tonumber(redis.call('hget', settings_key, 'groupTimeout'))\\nrefresh_expiration(0, 0, groupTimeout)\\n\\nreturn reservoir\\n","init.lua":"local clear = tonumber(ARGV[num_static_argv + 1])\\nlocal limiter_version = ARGV[num_static_argv + 2]\\nlocal num_local_argv = num_static_argv + 2\\n\\nif clear == 1 then\\n  redis.call('del', unpack(KEYS))\\nend\\n\\nif redis.call('exists', settings_key) == 0 then\\n  -- Create\\n  local args = {'hmset', settings_key}\\n\\n  for i = num_local_argv + 1, #ARGV do\\n    table.insert(args, ARGV[i])\\n  end\\n\\n  redis.call(unpack(args))\\n  redis.call('hmset', settings_key,\\n    'nextRequest', now,\\n    'lastReservoirRefresh', now,\\n    'lastReservoirIncrease', now,\\n    'running', 0,\\n    'done', 0,\\n    'unblockTime', 0,\\n    'capacityPriorityCounter', 0\\n  )\\n\\nelse\\n  -- Apply migrations\\n  local settings = redis.call('hmget', settings_key,\\n    'id',\\n    'version'\\n  )\\n  local id = settings[1]\\n  local current_version = settings[2]\\n\\n  if current_version ~= limiter_version then\\n    local version_digits = {}\\n    for k, v in string.gmatch(current_version, \\"([^.]+)\\") do\\n      table.insert(version_digits, tonumber(k))\\n    end\\n\\n    -- 2.10.0\\n    if version_digits[2] < 10 then\\n      redis.call('hsetnx', settings_key, 'reservoirRefreshInterval', '')\\n      redis.call('hsetnx', settings_key, 'reservoirRefreshAmount', '')\\n      redis.call('hsetnx', settings_key, 'lastReservoirRefresh', '')\\n      redis.call('hsetnx', settings_key, 'done', 0)\\n      redis.call('hset', settings_key, 'version', '2.10.0')\\n    end\\n\\n    -- 2.11.1\\n    if version_digits[2] < 11 or (version_digits[2] == 11 and version_digits[3] < 1) then\\n      if redis.call('hstrlen', settings_key, 'lastReservoirRefresh') == 0 then\\n        redis.call('hmset', settings_key,\\n          'lastReservoirRefresh', now,\\n          'version', '2.11.1'\\n        )\\n      end\\n    end\\n\\n    -- 2.14.0\\n    if version_digits[2] < 14 then\\n      local old_running_key = 'b_'..id..'_running'\\n      local old_executing_key = 'b_'..id..'_executing'\\n\\n      if redis.call('exists', old_running_key) == 1 then\\n        redis.call('rename', old_running_key, job_weights_key)\\n      end\\n      if redis.call('exists', old_executing_key) == 1 then\\n        redis.call('rename', old_executing_key, job_expirations_key)\\n      end\\n      redis.call('hset', settings_key, 'version', '2.14.0')\\n    end\\n\\n    -- 2.15.2\\n    if version_digits[2] < 15 or (version_digits[2] == 15 and version_digits[3] < 2) then\\n      redis.call('hsetnx', settings_key, 'capacityPriorityCounter', 0)\\n      redis.call('hset', settings_key, 'version', '2.15.2')\\n    end\\n\\n    -- 2.17.0\\n    if version_digits[2] < 17 then\\n      redis.call('hsetnx', settings_key, 'clientTimeout', 10000)\\n      redis.call('hset', settings_key, 'version', '2.17.0')\\n    end\\n\\n    -- 2.18.0\\n    if version_digits[2] < 18 then\\n      redis.call('hsetnx', settings_key, 'reservoirIncreaseInterval', '')\\n      redis.call('hsetnx', settings_key, 'reservoirIncreaseAmount', '')\\n      redis.call('hsetnx', settings_key, 'reservoirIncreaseMaximum', '')\\n      redis.call('hsetnx', settings_key, 'lastReservoirIncrease', now)\\n      redis.call('hset', settings_key, 'version', '2.18.0')\\n    end\\n\\n  end\\n\\n  process_tick(now, false)\\nend\\n\\nlocal groupTimeout = tonumber(redis.call('hget', settings_key, 'groupTimeout'))\\nrefresh_expiration(0, 0, groupTimeout)\\n\\nreturn {}\\n","process_tick.lua":"local process_tick = function (now, always_publish)\\n\\n  local compute_capacity = function (maxConcurrent, running, reservoir)\\n    if maxConcurrent ~= nil and reservoir ~= nil then\\n      return math.min((maxConcurrent - running), reservoir)\\n    elseif maxConcurrent ~= nil then\\n      return maxConcurrent - running\\n    elseif reservoir ~= nil then\\n      return reservoir\\n    else\\n      return nil\\n    end\\n  end\\n\\n  local settings = redis.call('hmget', settings_key,\\n    'id',\\n    'maxConcurrent',\\n    'running',\\n    'reservoir',\\n    'reservoirRefreshInterval',\\n    'reservoirRefreshAmount',\\n    'lastReservoirRefresh',\\n    'reservoirIncreaseInterval',\\n    'reservoirIncreaseAmount',\\n    'reservoirIncreaseMaximum',\\n    'lastReservoirIncrease',\\n    'capacityPriorityCounter',\\n    'clientTimeout'\\n  )\\n  local id = settings[1]\\n  local maxConcurrent = tonumber(settings[2])\\n  local running = tonumber(settings[3])\\n  local reservoir = tonumber(settings[4])\\n  local reservoirRefreshInterval = tonumber(settings[5])\\n  local reservoirRefreshAmount = tonumber(settings[6])\\n  local lastReservoirRefresh = tonumber(settings[7])\\n  local reservoirIncreaseInterval = tonumber(settings[8])\\n  local reservoirIncreaseAmount = tonumber(settings[9])\\n  local reservoirIncreaseMaximum = tonumber(settings[10])\\n  local lastReservoirIncrease = tonumber(settings[11])\\n  local capacityPriorityCounter = tonumber(settings[12])\\n  local clientTimeout = tonumber(settings[13])\\n\\n  local initial_capacity = compute_capacity(maxConcurrent, running, reservoir)\\n\\n  --\\n  -- Process 'running' changes\\n  --\\n  local expired = redis.call('zrangebyscore', job_expirations_key, '-inf', '('..now)\\n\\n  if #expired > 0 then\\n    redis.call('zremrangebyscore', job_expirations_key, '-inf', '('..now)\\n\\n    local flush_batch = function (batch, acc)\\n      local weights = redis.call('hmget', job_weights_key, unpack(batch))\\n                      redis.call('hdel',  job_weights_key, unpack(batch))\\n      local clients = redis.call('hmget', job_clients_key, unpack(batch))\\n                      redis.call('hdel',  job_clients_key, unpack(batch))\\n\\n      -- Calculate sum of removed weights\\n      for i = 1, #weights do\\n        acc['total'] = acc['total'] + (tonumber(weights[i]) or 0)\\n      end\\n\\n      -- Calculate sum of removed weights by client\\n      local client_weights = {}\\n      for i = 1, #clients do\\n        local removed = tonumber(weights[i]) or 0\\n        if removed > 0 then\\n          acc['client_weights'][clients[i]] = (acc['client_weights'][clients[i]] or 0) + removed\\n        end\\n      end\\n    end\\n\\n    local acc = {\\n      ['total'] = 0,\\n      ['client_weights'] = {}\\n    }\\n    local batch_size = 1000\\n\\n    -- Compute changes to Zsets and apply changes to Hashes\\n    for i = 1, #expired, batch_size do\\n      local batch = {}\\n      for j = i, math.min(i + batch_size - 1, #expired) do\\n        table.insert(batch, expired[j])\\n      end\\n\\n      flush_batch(batch, acc)\\n    end\\n\\n    -- Apply changes to Zsets\\n    if acc['total'] > 0 then\\n      redis.call('hincrby', settings_key, 'done', acc['total'])\\n      running = tonumber(redis.call('hincrby', settings_key, 'running', -acc['total']))\\n    end\\n\\n    for client, weight in pairs(acc['client_weights']) do\\n      redis.call('zincrby', client_running_key, -weight, client)\\n    end\\n  end\\n\\n  --\\n  -- Process 'reservoir' changes\\n  --\\n  local reservoirRefreshActive = reservoirRefreshInterval ~= nil and reservoirRefreshAmount ~= nil\\n  if reservoirRefreshActive and now >= lastReservoirRefresh + reservoirRefreshInterval then\\n    reservoir = reservoirRefreshAmount\\n    redis.call('hmset', settings_key,\\n      'reservoir', reservoir,\\n      'lastReservoirRefresh', now\\n    )\\n  end\\n\\n  local reservoirIncreaseActive = reservoirIncreaseInterval ~= nil and reservoirIncreaseAmount ~= nil\\n  if reservoirIncreaseActive and now >= lastReservoirIncrease + reservoirIncreaseInterval then\\n    local num_intervals = math.floor((now - lastReservoirIncrease) / reservoirIncreaseInterval)\\n    local incr = reservoirIncreaseAmount * num_intervals\\n    if reservoirIncreaseMaximum ~= nil then\\n      incr = math.min(incr, reservoirIncreaseMaximum - (reservoir or 0))\\n    end\\n    if incr > 0 then\\n      reservoir = (reservoir or 0) + incr\\n    end\\n    redis.call('hmset', settings_key,\\n      'reservoir', reservoir,\\n      'lastReservoirIncrease', lastReservoirIncrease + (num_intervals * reservoirIncreaseInterval)\\n    )\\n  end\\n\\n  --\\n  -- Clear unresponsive clients\\n  --\\n  local unresponsive = redis.call('zrangebyscore', client_last_seen_key, '-inf', (now - clientTimeout))\\n  local unresponsive_lookup = {}\\n  local terminated_clients = {}\\n  for i = 1, #unresponsive do\\n    unresponsive_lookup[unresponsive[i]] = true\\n    if tonumber(redis.call('zscore', client_running_key, unresponsive[i])) == 0 then\\n      table.insert(terminated_clients, unresponsive[i])\\n    end\\n  end\\n  if #terminated_clients > 0 then\\n    redis.call('zrem', client_running_key,         unpack(terminated_clients))\\n    redis.call('hdel', client_num_queued_key,      unpack(terminated_clients))\\n    redis.call('zrem', client_last_registered_key, unpack(terminated_clients))\\n    redis.call('zrem', client_last_seen_key,       unpack(terminated_clients))\\n  end\\n\\n  --\\n  -- Broadcast capacity changes\\n  --\\n  local final_capacity = compute_capacity(maxConcurrent, running, reservoir)\\n\\n  if always_publish or (initial_capacity ~= nil and final_capacity == nil) then\\n    -- always_publish or was not unlimited, now unlimited\\n    redis.call('publish', 'b_'..id, 'capacity:'..(final_capacity or ''))\\n\\n  elseif initial_capacity ~= nil and final_capacity ~= nil and final_capacity > initial_capacity then\\n    -- capacity was increased\\n    -- send the capacity message to the limiter having the lowest number of running jobs\\n    -- the tiebreaker is the limiter having not registered a job in the longest time\\n\\n    local lowest_concurrency_value = nil\\n    local lowest_concurrency_clients = {}\\n    local lowest_concurrency_last_registered = {}\\n    local client_concurrencies = redis.call('zrange', client_running_key, 0, -1, 'withscores')\\n\\n    for i = 1, #client_concurrencies, 2 do\\n      local client = client_concurrencies[i]\\n      local concurrency = tonumber(client_concurrencies[i+1])\\n\\n      if (\\n        lowest_concurrency_value == nil or lowest_concurrency_value == concurrency\\n      ) and (\\n        not unresponsive_lookup[client]\\n      ) and (\\n        tonumber(redis.call('hget', client_num_queued_key, client)) > 0\\n      ) then\\n        lowest_concurrency_value = concurrency\\n        table.insert(lowest_concurrency_clients, client)\\n        local last_registered = tonumber(redis.call('zscore', client_last_registered_key, client))\\n        table.insert(lowest_concurrency_last_registered, last_registered)\\n      end\\n    end\\n\\n    if #lowest_concurrency_clients > 0 then\\n      local position = 1\\n      local earliest = lowest_concurrency_last_registered[1]\\n\\n      for i,v in ipairs(lowest_concurrency_last_registered) do\\n        if v < earliest then\\n          position = i\\n          earliest = v\\n        end\\n      end\\n\\n      local next_client = lowest_concurrency_clients[position]\\n      redis.call('publish', 'b_'..id,\\n        'capacity-priority:'..(final_capacity or '')..\\n        ':'..next_client..\\n        ':'..capacityPriorityCounter\\n      )\\n      redis.call('hincrby', settings_key, 'capacityPriorityCounter', '1')\\n    else\\n      redis.call('publish', 'b_'..id, 'capacity:'..(final_capacity or ''))\\n    end\\n  end\\n\\n  return {\\n    ['capacity'] = final_capacity,\\n    ['running'] = running,\\n    ['reservoir'] = reservoir\\n  }\\nend\\n","queued.lua":"local clientTimeout = tonumber(redis.call('hget', settings_key, 'clientTimeout'))\\nlocal valid_clients = redis.call('zrangebyscore', client_last_seen_key, (now - clientTimeout), 'inf')\\nlocal client_queued = redis.call('hmget', client_num_queued_key, unpack(valid_clients))\\n\\nlocal sum = 0\\nfor i = 1, #client_queued do\\n  sum = sum + tonumber(client_queued[i])\\nend\\n\\nreturn sum\\n","refresh_expiration.lua":"local refresh_expiration = function (now, nextRequest, groupTimeout)\\n\\n  if groupTimeout ~= nil then\\n    local ttl = (nextRequest + groupTimeout) - now\\n\\n    for i = 1, #KEYS do\\n      redis.call('pexpire', KEYS[i], ttl)\\n    end\\n  end\\n\\nend\\n","refs.lua":"local settings_key = KEYS[1]\\nlocal job_weights_key = KEYS[2]\\nlocal job_expirations_key = KEYS[3]\\nlocal job_clients_key = KEYS[4]\\nlocal client_running_key = KEYS[5]\\nlocal client_num_queued_key = KEYS[6]\\nlocal client_last_registered_key = KEYS[7]\\nlocal client_last_seen_key = KEYS[8]\\n\\nlocal now = tonumber(ARGV[1])\\nlocal client = ARGV[2]\\n\\nlocal num_static_argv = 2\\n","register.lua":"local index = ARGV[num_static_argv + 1]\\nlocal weight = tonumber(ARGV[num_static_argv + 2])\\nlocal expiration = tonumber(ARGV[num_static_argv + 3])\\n\\nlocal state = process_tick(now, false)\\nlocal capacity = state['capacity']\\nlocal reservoir = state['reservoir']\\n\\nlocal settings = redis.call('hmget', settings_key,\\n  'nextRequest',\\n  'minTime',\\n  'groupTimeout'\\n)\\nlocal nextRequest = tonumber(settings[1])\\nlocal minTime = tonumber(settings[2])\\nlocal groupTimeout = tonumber(settings[3])\\n\\nif conditions_check(capacity, weight) then\\n\\n  redis.call('hincrby', settings_key, 'running', weight)\\n  redis.call('hset', job_weights_key, index, weight)\\n  if expiration ~= nil then\\n    redis.call('zadd', job_expirations_key, now + expiration, index)\\n  end\\n  redis.call('hset', job_clients_key, index, client)\\n  redis.call('zincrby', client_running_key, weight, client)\\n  redis.call('hincrby', client_num_queued_key, client, -1)\\n  redis.call('zadd', client_last_registered_key, now, client)\\n\\n  local wait = math.max(nextRequest - now, 0)\\n  local newNextRequest = now + wait + minTime\\n\\n  if reservoir == nil then\\n    redis.call('hset', settings_key,\\n      'nextRequest', newNextRequest\\n    )\\n  else\\n    reservoir = reservoir - weight\\n    redis.call('hmset', settings_key,\\n      'reservoir', reservoir,\\n      'nextRequest', newNextRequest\\n    )\\n  end\\n\\n  refresh_expiration(now, newNextRequest, groupTimeout)\\n\\n  return {true, wait, reservoir}\\n\\nelse\\n  return {false}\\nend\\n","register_client.lua":"local queued = tonumber(ARGV[num_static_argv + 1])\\n\\n-- Could have been re-registered concurrently\\nif not redis.call('zscore', client_last_seen_key, client) then\\n  redis.call('zadd', client_running_key, 0, client)\\n  redis.call('hset', client_num_queued_key, client, queued)\\n  redis.call('zadd', client_last_registered_key, 0, client)\\nend\\n\\nredis.call('zadd', client_last_seen_key, now, client)\\n\\nreturn {}\\n","running.lua":"return process_tick(now, false)['running']\\n","submit.lua":"local queueLength = tonumber(ARGV[num_static_argv + 1])\\nlocal weight = tonumber(ARGV[num_static_argv + 2])\\n\\nlocal capacity = process_tick(now, false)['capacity']\\n\\nlocal settings = redis.call('hmget', settings_key,\\n  'id',\\n  'maxConcurrent',\\n  'highWater',\\n  'nextRequest',\\n  'strategy',\\n  'unblockTime',\\n  'penalty',\\n  'minTime',\\n  'groupTimeout'\\n)\\nlocal id = settings[1]\\nlocal maxConcurrent = tonumber(settings[2])\\nlocal highWater = tonumber(settings[3])\\nlocal nextRequest = tonumber(settings[4])\\nlocal strategy = tonumber(settings[5])\\nlocal unblockTime = tonumber(settings[6])\\nlocal penalty = tonumber(settings[7])\\nlocal minTime = tonumber(settings[8])\\nlocal groupTimeout = tonumber(settings[9])\\n\\nif maxConcurrent ~= nil and weight > maxConcurrent then\\n  return redis.error_reply('OVERWEIGHT:'..weight..':'..maxConcurrent)\\nend\\n\\nlocal reachedHWM = (highWater ~= nil and queueLength == highWater\\n  and not (\\n    conditions_check(capacity, weight)\\n    and nextRequest - now <= 0\\n  )\\n)\\n\\nlocal blocked = strategy == 3 and (reachedHWM or unblockTime >= now)\\n\\nif blocked then\\n  local computedPenalty = penalty\\n  if computedPenalty == nil then\\n    if minTime == 0 then\\n      computedPenalty = 5000\\n    else\\n      computedPenalty = 15 * minTime\\n    end\\n  end\\n\\n  local newNextRequest = now + computedPenalty + minTime\\n\\n  redis.call('hmset', settings_key,\\n    'unblockTime', now + computedPenalty,\\n    'nextRequest', newNextRequest\\n  )\\n\\n  local clients_queued_reset = redis.call('hkeys', client_num_queued_key)\\n  local queued_reset = {}\\n  for i = 1, #clients_queued_reset do\\n    table.insert(queued_reset, clients_queued_reset[i])\\n    table.insert(queued_reset, 0)\\n  end\\n  redis.call('hmset', client_num_queued_key, unpack(queued_reset))\\n\\n  redis.call('publish', 'b_'..id, 'blocked:')\\n\\n  refresh_expiration(now, newNextRequest, groupTimeout)\\nend\\n\\nif not blocked and not reachedHWM then\\n  redis.call('hincrby', client_num_queued_key, client, 1)\\nend\\n\\nreturn {reachedHWM, blocked, strategy}\\n","update_settings.lua":"local args = {'hmset', settings_key}\\n\\nfor i = num_static_argv + 1, #ARGV do\\n  table.insert(args, ARGV[i])\\nend\\n\\nredis.call(unpack(args))\\n\\nprocess_tick(now, true)\\n\\nlocal groupTimeout = tonumber(redis.call('hget', settings_key, 'groupTimeout'))\\nrefresh_expiration(0, 0, groupTimeout)\\n\\nreturn {}\\n","validate_client.lua":"if not redis.call('zscore', client_last_seen_key, client) then\\n  return redis.error_reply('UNKNOWN_CLIENT')\\nend\\n\\nredis.call('zadd', client_last_seen_key, now, client)\\n","validate_keys.lua":"if not (redis.call('exists', settings_key) == 1) then\\n  return redis.error_reply('SETTINGS_KEY_NOT_FOUND')\\nend\\n"}`)},75705:c=>{c.exports={i:"2.19.5"}}}]);
